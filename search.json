[
  {
    "objectID": "agenda.html",
    "href": "agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "Programming basics recap\nMore Julia fundamentals\n\nThe type system & multiple dispatch\nCreating packages, environments and project organization\nPerformance optimization\n\nCode organization and git / github\n\n\n\n\nThe official Julia documentation\nThe Julia discourse forum\nYoutube video on developing Julia packages\nThe git and github documentation\nOnline git tutorials"
  },
  {
    "objectID": "agenda.html#data-science-toolkit",
    "href": "agenda.html#data-science-toolkit",
    "title": "Agenda",
    "section": "Data Science Toolkit",
    "text": "Data Science Toolkit\n\nTabular data and DataFrames.jl\nVisualization and Makie.jl\nNetwork analysis and Graphs.jl\n\n\nReferences & Materials\n\nThe docs: Makie.jl, DataFrames.jl, Graphs.jl\nThe Beautiful Makie website, with many nice plotting examples\nThe Julia Data Science online book, containing many simple examples\nThe 2022 book Julia for Data Analysis\nThe blog of Bogumli Kaminski, author of the DataFrames.jl package"
  },
  {
    "objectID": "agenda.html#bayesian-modeling",
    "href": "agenda.html#bayesian-modeling",
    "title": "Agenda",
    "section": "Bayesian Modeling",
    "text": "Bayesian Modeling\n\nProbabilistic programming with Turing.jl\nProbabilistic programming with stan\nLow-level interface with LogDensityProblems.jl, TransformVariables.jl and DynamicHMC.jl\n\n\nReferences & Materials\n\nThe book Statistical Rethinking and Youtube lecture by Richard McElreath\nThe book Regression and Other Stories by Andrew Gelman et al.\nThe excellent Stan documentation"
  },
  {
    "objectID": "agenda.html#project-topics",
    "href": "agenda.html#project-topics",
    "title": "Agenda",
    "section": "Project Topics",
    "text": "Project Topics\n\nMain path analysis and MainPaths.jl\nPatent analytics\n\nJuliaPatents: PatentsBase.jl, PatentsLens.jl, PatentsLandscapes.jl\nData sources: EPO PATSTAT, Lens.org\n\nSurvey analysis"
  },
  {
    "objectID": "agenda.html#further-topics",
    "href": "agenda.html#further-topics",
    "title": "Agenda",
    "section": "Further Topics",
    "text": "Further Topics\n\nAgent-based models and Agents.jl\nDifferential equation models and DifferentialEquations.jl"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Julia",
    "section": "",
    "text": "This website contains materials used in a self-organized learning endeavour that includes programming (primarily in the Julia language), statistics (primarily of the Bayesian kind) and all other things that are of interest to us (primarily network analysis and patent analytics)."
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html",
    "href": "pages/bayes/coinflip_ldp.html",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "",
    "text": "This is a tutorial on how to use the LogDensityProblems.jl ecosystem for Bayesian inference. Compared to other packages, such as Turing.jl, this approach is a bit more low-level, with the upside of being more hackable and insightful for learning."
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html#setup",
    "href": "pages/bayes/coinflip_ldp.html#setup",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "Setup",
    "text": "Setup\nFor this exercise, we’re interested in performing inference on a simple process where a possibly biased coin is flipped \\(N=100\\) times. More formally, we could state this like so:\n\\[\ny_i \\sim \\mathrm{Bernoulli}(p) \\textrm{ for } i = 1,2,...100\n\\]\nWe start by simulating data from a Bernoulli distribution with the probability of heads set to \\(p = 0.7\\), which for the inverse problem is going to be the unknown quantity of interest to be inferred from observed data.\n\nusing Distributions\n\n\nN = 100\np = 0.7\nd = Bernoulli(p)\ndata = rand(d, N);"
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html#model-definition",
    "href": "pages/bayes/coinflip_ldp.html#model-definition",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "Model definition",
    "text": "Model definition\nHaving simulated data for inference, we now proceed to the model definition using the LogDensityProblems interface package. As we assume that the individual coinflips are independent from one another, the exact sequence of flips is irrelevant and we just need to store the total number of flips, \\(N\\), and the number of heads, which we call \\(y\\). We store this information in a struct called CoinflipProblem, for which we also create a constructor that extracts the necessary information from a sequence of flips.\n\nstruct CoinflipProblem\n  N::Int\n  y::Int\nend\n\nfunction CoinflipProblem(data::AbstractVector{Bool})\n  N, y = length(data), sum(data)\n  CoinflipProblem(N, y)\nend;\n\nWe now make our problem struct callable on an input parameter \\(\\theta\\) at which to evaluate the (unnormalized) log joint probability density of the posterior distribution. Next to the likelihood function which makes use of the information from the data, we also need to specify a prior distribution for the unknown quantities. Here, we’re going to be broadly skeptical of extremely biased coins and use a \\(Beta(2,2)\\) prior:\n\nusing CairoMakie\nplot(Beta(2,2))\n\n\n\n\n\nfunction (problem::CoinflipProblem)(θ)\n  (; N, y) = problem\n  (; p) = θ\n  logprior = logpdf(Beta(2,2), p)\n  loglikelihood = logpdf(Binomial(N, p), y)\n  logprior + loglikelihood\nend  \n\nWe can now instantiate our problem on the data and evaluate the joint logdensity of a fair coinflip with \\(p = 0.5\\):\n\nproblem = CoinflipProblem(data)\nproblem((; p=0.5))\n\n-9.45264926936576"
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html#model-estimation",
    "href": "pages/bayes/coinflip_ldp.html#model-estimation",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "Model estimation",
    "text": "Model estimation\nHaving defined a way to evaluate the posterior density for a given parameter value, we now proceed to set up a sampling-based numeric estimation procedure via Hamiltonian\nMonte Carlo (HMC) using the LogDensityProblems suite of packages. HMC operates on the unconstrained reals but our parameter \\(p\\) is confined to the unit interval \\((0,1)\\) so we need an appropriate transformation, which is conveniently available in the TransformedLogDensity package. HMC furthermore requires the gradient of the posterior density, which we get with an automatic differentiation package, in this case ForwardDiff.\n\nusing LogDensityProblems\nusing TransformVariables, TransformedLogDensities\nusing LogDensityProblemsAD, ForwardDiff\n\ntransformation = as((p=as_unit_interval,))\ntran = TransformedLogDensity(transformation, problem)\ngrad = ADgradient(:ForwardDiff, tran)\n\nForwardDiff AD wrapper for TransformedLogDensity of dimension 1, w/ chunk size 1\n\n\nWe can now evaluate the logdensity and its gradient:\n\nLogDensityProblems.logdensity_and_gradient(grad, zeros(1))\n\n(-10.838943630485652, [19.0])\n\n\nWith this in place, we can now draw a large number of samples (say, \\(S=2000\\)) from the posterior distribution using the HMC implementation in DynamicHMC as an approximation. We use the ThreadsX package to sample \\(k\\) chains in parallel:\n\nusing Random\nusing DynamicHMC\nusing ThreadsX\n\nfunction sample(grad, S, k; rng=Random.default_rng()) \n   ThreadsX.map(1:k) do _\n     mcmc_with_warmup(rng, grad, S; reporter=NoProgressReport())\n   end\nend\n\nresult = sample(grad, 2000, 4)\n\n4-element Vector{NamedTuple{(:posterior_matrix, :tree_statistics, :κ, :ϵ), Tuple{Matrix{Float64}, Vector{DynamicHMC.TreeStatisticsNUTS}, GaussianKineticEnergy{LinearAlgebra.Diagonal{Float64, Vector{Float64}}, LinearAlgebra.Diagonal{Float64, Vector{Float64}}}, Float64}}}:\n (posterior_matrix = [0.7316955710843734 0.7953750279234975 … 0.9480882394726355 1.2886658934256674], tree_statistics = [DynamicHMC.TreeStatisticsNUTS(-3.987395143259178, 2, turning at positions 0:3, 0.9699295944155376, 3, DynamicHMC.Directions(0xc5617657)), DynamicHMC.TreeStatisticsNUTS(-3.778349561280023, 2, turning at positions 0:3, 0.9963348587727863, 3, DynamicHMC.Directions(0xc1dada97)), DynamicHMC.TreeStatisticsNUTS(-3.8902061125521983, 1, turning at positions 1:2, 0.9734735230610577, 3, DynamicHMC.Directions(0xb204c432)), DynamicHMC.TreeStatisticsNUTS(-4.528679612179594, 1, turning at positions -1:-2, 0.9034794518521089, 3, DynamicHMC.Directions(0x65729095)), DynamicHMC.TreeStatisticsNUTS(-4.493276491920113, 2, turning at positions -1:2, 0.9999999999999999, 3, DynamicHMC.Directions(0xb139ac2e)), DynamicHMC.TreeStatisticsNUTS(-3.8012387054704013, 2, turning at positions -3:0, 0.990794125038322, 3, DynamicHMC.Directions(0xe89808b8)), DynamicHMC.TreeStatisticsNUTS(-4.123024420363847, 2, turning at positions -3:0, 0.9420667089222524, 3, DynamicHMC.Directions(0x5854065c)), DynamicHMC.TreeStatisticsNUTS(-3.8459751566261158, 2, turning at positions -3:0, 0.9858123564546247, 3, DynamicHMC.Directions(0x81021be4)), DynamicHMC.TreeStatisticsNUTS(-5.028100046251067, 1, turning at positions 1:2, 0.8190876410400332, 3, DynamicHMC.Directions(0xd8adaed6)), DynamicHMC.TreeStatisticsNUTS(-5.301640685121536, 1, turning at positions -1:0, 0.81581498914529, 1, DynamicHMC.Directions(0xb8386236))  …  DynamicHMC.TreeStatisticsNUTS(-5.4242730989853, 2, turning at positions 0:3, 0.859281250466915, 3, DynamicHMC.Directions(0x2e1f9963)), DynamicHMC.TreeStatisticsNUTS(-5.1153723391799755, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0x040b8ff1)), DynamicHMC.TreeStatisticsNUTS(-5.323935422022056, 1, turning at positions -1:0, 0.7799120236361637, 1, DynamicHMC.Directions(0xb084e14a)), DynamicHMC.TreeStatisticsNUTS(-5.374894100962107, 1, turning at positions -1:0, 1.0, 1, DynamicHMC.Directions(0x4473ec48)), DynamicHMC.TreeStatisticsNUTS(-4.668976369955247, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0xb58b14ad)), DynamicHMC.TreeStatisticsNUTS(-4.033043407653454, 2, turning at positions -1:2, 0.9999999999999999, 3, DynamicHMC.Directions(0xcefa8d0e)), DynamicHMC.TreeStatisticsNUTS(-3.7692524006051107, 1, turning at positions 2:3, 0.9997763918361962, 3, DynamicHMC.Directions(0x0b171fc7)), DynamicHMC.TreeStatisticsNUTS(-3.763930832313354, 1, turning at positions -1:-2, 0.9953207682149062, 3, DynamicHMC.Directions(0x9c1a8195)), DynamicHMC.TreeStatisticsNUTS(-6.308323432981946, 2, turning at positions -3:0, 0.6699455716640964, 3, DynamicHMC.Directions(0xf35f52d4)), DynamicHMC.TreeStatisticsNUTS(-6.769892463106961, 1, turning at positions 1:2, 0.6624346904689055, 3, DynamicHMC.Directions(0x128f4a86))], κ = Gaussian kinetic energy (Diagonal), √diag(M⁻¹): [0.23175310411867012], ϵ = 0.882186506082379)\n (posterior_matrix = [0.8909923608858303 0.8711979452493371 … 0.6786303155875957 0.6017906794490779], tree_statistics = [DynamicHMC.TreeStatisticsNUTS(-4.7625770893636545, 2, turning at positions -3:0, 0.8996642225624587, 3, DynamicHMC.Directions(0x4fc87680)), DynamicHMC.TreeStatisticsNUTS(-3.917016249075253, 2, turning at positions -2:1, 0.9999999999999999, 3, DynamicHMC.Directions(0xe8f01df1)), DynamicHMC.TreeStatisticsNUTS(-3.917754280076351, 1, turning at positions -2:-3, 0.9881038162307, 3, DynamicHMC.Directions(0x01cccd94)), DynamicHMC.TreeStatisticsNUTS(-4.883208947723692, 1, turning at positions 1:2, 0.6897384373500723, 3, DynamicHMC.Directions(0xd0e09336)), DynamicHMC.TreeStatisticsNUTS(-3.886085281065849, 1, turning at positions 1:2, 0.9796216305375718, 3, DynamicHMC.Directions(0xb28467d6)), DynamicHMC.TreeStatisticsNUTS(-4.1018754401010495, 2, turning at positions -3:0, 0.9573862314200277, 3, DynamicHMC.Directions(0x701484b8)), DynamicHMC.TreeStatisticsNUTS(-4.388484385835859, 1, turning at positions 1:2, 0.9150049705339915, 3, DynamicHMC.Directions(0x2ec58c0a)), DynamicHMC.TreeStatisticsNUTS(-4.112187537958462, 1, turning at positions -2:-3, 0.9899839128819005, 3, DynamicHMC.Directions(0xd4ba7de8)), DynamicHMC.TreeStatisticsNUTS(-5.309163316030236, 2, turning at positions -3:0, 0.7587196962715553, 3, DynamicHMC.Directions(0x857a3434)), DynamicHMC.TreeStatisticsNUTS(-4.08682809621471, 1, turning at positions -1:0, 0.92116173099068, 1, DynamicHMC.Directions(0xf156d898))  …  DynamicHMC.TreeStatisticsNUTS(-3.8274474489338095, 1, turning at positions -2:-3, 0.9934810615411038, 3, DynamicHMC.Directions(0x9d8e82a4)), DynamicHMC.TreeStatisticsNUTS(-4.140197706108529, 1, turning at positions 1:2, 0.8903949717507089, 3, DynamicHMC.Directions(0x4b4477d6)), DynamicHMC.TreeStatisticsNUTS(-3.887970593900849, 1, turning at positions -1:-2, 0.9715928376839659, 3, DynamicHMC.Directions(0x296419e5)), DynamicHMC.TreeStatisticsNUTS(-5.488591567226338, 1, turning at positions 1:2, 0.7372804858552003, 3, DynamicHMC.Directions(0x41b87946)), DynamicHMC.TreeStatisticsNUTS(-4.6066889170850365, 1, turning at positions 2:3, 0.9999999999999999, 3, DynamicHMC.Directions(0x0e9122f7)), DynamicHMC.TreeStatisticsNUTS(-4.111947099645159, 2, turning at positions -3:0, 0.9402404242981285, 3, DynamicHMC.Directions(0x1a2223d4)), DynamicHMC.TreeStatisticsNUTS(-4.1193127096655795, 1, turning at positions -1:0, 0.9243487391962859, 1, DynamicHMC.Directions(0x92f6dc8a)), DynamicHMC.TreeStatisticsNUTS(-5.198915342204001, 1, turning at positions 0:1, 0.6133385085721722, 1, DynamicHMC.Directions(0x7d22a7d9)), DynamicHMC.TreeStatisticsNUTS(-4.026493090553238, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0xc00469db)), DynamicHMC.TreeStatisticsNUTS(-4.047588590022625, 1, turning at positions -1:0, 0.9354769554644085, 1, DynamicHMC.Directions(0x72ebd2ba))], κ = Gaussian kinetic energy (Diagonal), √diag(M⁻¹): [0.21863136545544126], ϵ = 1.0333276501191273)\n (posterior_matrix = [0.23002538108990778 0.7510848245570663 … 0.35029964768761823 0.21097359051380243], tree_statistics = [DynamicHMC.TreeStatisticsNUTS(-10.279763509441267, 2, turning at positions 0:3, 0.30842234854436157, 3, DynamicHMC.Directions(0x9b211aa7)), DynamicHMC.TreeStatisticsNUTS(-6.173022225628905, 1, turning at positions -2:-3, 0.9999999999999999, 3, DynamicHMC.Directions(0x06dd621c)), DynamicHMC.TreeStatisticsNUTS(-3.7861232292908347, 2, turning at positions 0:3, 0.98821556437507, 3, DynamicHMC.Directions(0x16e9a9f7)), DynamicHMC.TreeStatisticsNUTS(-4.243898176925417, 1, turning at positions -1:-2, 0.8797364495620252, 3, DynamicHMC.Directions(0xe78610f1)), DynamicHMC.TreeStatisticsNUTS(-4.771009762451223, 1, turning at positions 0:1, 0.8655355093159067, 1, DynamicHMC.Directions(0x874bfaaf)), DynamicHMC.TreeStatisticsNUTS(-4.423405686721482, 1, turning at positions -1:0, 1.0, 1, DynamicHMC.Directions(0x0fb8748a)), DynamicHMC.TreeStatisticsNUTS(-6.405539013122212, 2, turning at positions -3:0, 0.6903138346571257, 3, DynamicHMC.Directions(0x67ba4430)), DynamicHMC.TreeStatisticsNUTS(-6.566755701793206, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0x972604bb)), DynamicHMC.TreeStatisticsNUTS(-5.769192651731633, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0x040d4779)), DynamicHMC.TreeStatisticsNUTS(-5.186584474297659, 2, turning at positions -3:0, 0.9036571821535543, 3, DynamicHMC.Directions(0xe1e076c4))  …  DynamicHMC.TreeStatisticsNUTS(-4.576510552346747, 1, turning at positions 0:1, 0.8895930085177809, 1, DynamicHMC.Directions(0xa5b6b41f)), DynamicHMC.TreeStatisticsNUTS(-4.379319935926382, 1, turning at positions 2:3, 0.9884368306235493, 3, DynamicHMC.Directions(0xbd123e2b)), DynamicHMC.TreeStatisticsNUTS(-4.659610833607627, 1, turning at positions -1:-2, 0.8088193922604211, 3, DynamicHMC.Directions(0x82bb3b69)), DynamicHMC.TreeStatisticsNUTS(-4.3675881398895555, 1, turning at positions -1:0, 1.0, 1, DynamicHMC.Directions(0x34d797f4)), DynamicHMC.TreeStatisticsNUTS(-4.02314833011462, 1, turning at positions -1:0, 1.0, 1, DynamicHMC.Directions(0xa30d9466)), DynamicHMC.TreeStatisticsNUTS(-4.490120935042692, 1, turning at positions -1:0, 0.8310979638061257, 1, DynamicHMC.Directions(0x98cf1f18)), DynamicHMC.TreeStatisticsNUTS(-4.476317569984239, 2, turning at positions -1:2, 0.9999999999999999, 3, DynamicHMC.Directions(0x6fb91bf6)), DynamicHMC.TreeStatisticsNUTS(-4.875909665035234, 2, turning at positions 0:3, 0.8256657942716759, 3, DynamicHMC.Directions(0xc47ab653)), DynamicHMC.TreeStatisticsNUTS(-5.851032481293324, 2, turning at positions -2:1, 0.8250366397019558, 3, DynamicHMC.Directions(0x00cd4175)), DynamicHMC.TreeStatisticsNUTS(-7.9571609721441545, 1, turning at positions 0:1, 0.547254203085549, 1, DynamicHMC.Directions(0xd91bd3cb))], κ = Gaussian kinetic energy (Diagonal), √diag(M⁻¹): [0.21334715641117113], ϵ = 1.1271412920307733)\n (posterior_matrix = [0.7381386081990002 0.7894116705964282 … 0.5932153981372981 0.5932153981372981], tree_statistics = [DynamicHMC.TreeStatisticsNUTS(-3.7735229495703115, 2, turning at positions 0:3, 0.9944976000080126, 3, DynamicHMC.Directions(0xb02d21d3)), DynamicHMC.TreeStatisticsNUTS(-3.7565553052748353, 2, turning at positions -3:0, 0.9981673777412822, 3, DynamicHMC.Directions(0x683eee1c)), DynamicHMC.TreeStatisticsNUTS(-3.85902832913982, 1, turning at positions -1:-2, 0.9768273090511049, 3, DynamicHMC.Directions(0xda713445)), DynamicHMC.TreeStatisticsNUTS(-3.8581091283058293, 1, turning at positions -1:0, 0.9941002092746692, 1, DynamicHMC.Directions(0x19bd53d4)), DynamicHMC.TreeStatisticsNUTS(-4.0712930182919465, 1, turning at positions 0:1, 0.9383512947782306, 1, DynamicHMC.Directions(0x1461fbe1)), DynamicHMC.TreeStatisticsNUTS(-4.004796335549283, 2, turning at positions -1:2, 0.9999999999999999, 3, DynamicHMC.Directions(0x23cb1dbe)), DynamicHMC.TreeStatisticsNUTS(-3.959336800218275, 1, turning at positions -2:-3, 0.9833088864339841, 3, DynamicHMC.Directions(0x0da1661c)), DynamicHMC.TreeStatisticsNUTS(-3.8245150679187767, 1, turning at positions 0:1, 0.99378312691671, 1, DynamicHMC.Directions(0xbd6ef515)), DynamicHMC.TreeStatisticsNUTS(-4.07332474126454, 1, turning at positions 0:1, 0.9302595233429217, 1, DynamicHMC.Directions(0x50b7e0dd)), DynamicHMC.TreeStatisticsNUTS(-4.0447773856994615, 2, turning at positions -2:1, 0.9999999999999999, 3, DynamicHMC.Directions(0x9502b5f1))  …  DynamicHMC.TreeStatisticsNUTS(-6.07604244154791, 1, turning at positions 0:1, 0.5769904320055523, 1, DynamicHMC.Directions(0x912df4e7)), DynamicHMC.TreeStatisticsNUTS(-4.981307751021244, 1, turning at positions 2:3, 0.9569519647260041, 3, DynamicHMC.Directions(0xd47c6f93)), DynamicHMC.TreeStatisticsNUTS(-4.15273719181174, 1, turning at positions 1:2, 0.9546057976500587, 3, DynamicHMC.Directions(0x3dddcaca)), DynamicHMC.TreeStatisticsNUTS(-5.411861058843045, 1, turning at positions -1:-2, 0.7278686903372571, 3, DynamicHMC.Directions(0x3e0a1189)), DynamicHMC.TreeStatisticsNUTS(-5.013709633992552, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0x2245f24b)), DynamicHMC.TreeStatisticsNUTS(-4.461856860131288, 2, turning at positions -1:2, 0.9451790347890627, 3, DynamicHMC.Directions(0xcabe5002)), DynamicHMC.TreeStatisticsNUTS(-3.831540335185889, 1, turning at positions 2:3, 0.9960925144060853, 3, DynamicHMC.Directions(0xb9c001ef)), DynamicHMC.TreeStatisticsNUTS(-3.8584360588301343, 1, turning at positions 1:2, 0.9770694203249205, 3, DynamicHMC.Directions(0xba077bee)), DynamicHMC.TreeStatisticsNUTS(-4.077771156372453, 1, turning at positions -1:0, 0.9300798597428996, 1, DynamicHMC.Directions(0x5136059e)), DynamicHMC.TreeStatisticsNUTS(-4.97549338472215, 1, turning at positions -1:0, 0.6950439494407777, 1, DynamicHMC.Directions(0xfd22bebe))], κ = Gaussian kinetic energy (Diagonal), √diag(M⁻¹): [0.2094930963526254], ϵ = 1.0409354080466415)\n\n\nThe result is a vector of length \\(k\\), each element of which contains for each chain the posterior samples as well as some statistics about the sampling procedure, which can be used to check if everything went as planned."
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html#model-checking",
    "href": "pages/bayes/coinflip_ldp.html#model-checking",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "Model checking",
    "text": "Model checking\nHaving obtained samples from the posterior distribution, we’re in principle ready to use our model for inference, i.e., answer the question of whether our coin is biased and by how much, and how certain we can be of the answer based on the data we have seen.\nHowever, before we jump to inference, it is good practice to perform some model checks: Our estimates rely on a numerical sampling scheme, which can fail rendering the results unreliable.\n\nusing MCMCDiagnosticTools\nusing DynamicHMC.Diagnostics\n\nFirst, we chan check the effective sample size (ess). In Markov chain monte carlo (MCMC) approaches, samples are often correlated, meaning that the total number of ‘effective’ samples is less than obtained by an uncorrelated sampling procedure.\n\ness, Rhat =  ess_rhat(stack_posterior_matrices(result))\n\n([2920.909239701402], [1.0017968286787173])\n\n\n\nsummarize_tree_statistics.(getfield.(result, :tree_statistics))\n\n4-element Vector{DynamicHMC.Diagnostics.TreeStatisticsSummary{Float64, NamedTuple{(:max_depth, :divergence, :turning), Tuple{Int64, Int64, Int64}}}}:\n Hamiltonian Monte Carlo sample of length 2000\n  acceptance rate mean: 0.93, 5/25/50/75/95%: 0.73 0.9 0.97 1.0 1.0\n  termination: divergence => 0%, max_depth => 0%, turning => 100%\n  depth: 0 => 0%, 1 => 62%, 2 => 38%\n Hamiltonian Monte Carlo sample of length 2000\n  acceptance rate mean: 0.91, 5/25/50/75/95%: 0.62 0.87 0.97 1.0 1.0\n  termination: divergence => 0%, max_depth => 0%, turning => 100%\n  depth: 0 => 0%, 1 => 65%, 2 => 35%\n Hamiltonian Monte Carlo sample of length 2000\n  acceptance rate mean: 0.9, 5/25/50/75/95%: 0.56 0.85 0.96 1.0 1.0\n  termination: divergence => 0%, max_depth => 0%, turning => 100%\n  depth: 0 => 0%, 1 => 60%, 2 => 40%\n Hamiltonian Monte Carlo sample of length 2000\n  acceptance rate mean: 0.92, 5/25/50/75/95%: 0.66 0.88 0.97 1.0 1.0\n  termination: divergence => 0%, max_depth => 0%, turning => 100%\n  depth: 0 => 0%, 1 => 64%, 2 => 36%"
  },
  {
    "objectID": "pages/bayes/coinflip_ldp.html#model-inference",
    "href": "pages/bayes/coinflip_ldp.html#model-inference",
    "title": "Bayesian inference for a sequence of coinflips",
    "section": "Model inference",
    "text": "Model inference\n\nusing StructArrays\n\nfunction posterior(result)\n  samples = eachcol(pool_posterior_matrices(result))\n  StructArray(transform.(transformation, samples))\nend\n\npost = posterior(result);\n\n\nfunction summarize(post)\n  m, s = round.((mean(post.p), std(post.p)); digits=2)\n  println(\"posterior mean: \", m)\n  println(\"posterior sd: \", s)\nend\n\nsummarize(post)\n\nposterior mean: 0.68\nposterior sd: 0.05\n\n\n\nfunction plot_inferred_vs_true(post, p_true)\n  fig = Figure(); ax = Axis(fig[1,1])\n  density!(ax, post.p; color=:grey20)\n  vlines!(ax, p_true; linewidth=2)\n  fig\nend\n\nplot_inferred_vs_true(post, p)"
  },
  {
    "objectID": "pages/programming_recap.html",
    "href": "pages/programming_recap.html",
    "title": "Programming Basics",
    "section": "",
    "text": "Exercise 1\nTask: Write a function that takes in a name and prints out a greeting, e.g., “Hello, Daniel”.\n\n\nSolution\ngreet(name) = println(\"Hello, $(name)!\")\ngreet(\"Daniel\")\n\n\nHello, Daniel!\n\n\n\n\nExercise 2\nTask: Write a function which greets the users whose name starts with a ‘D’ in Spanish, users whose name starts with a ‘C’ in German, and everyone else in English.\n\n\nSolution\nfunction greet(name)\n    firstletter = first(name)\n    if firstletter == 'D'\n        println(\"Hola, $(name)!\")\n    elseif firstletter == 'C'\n        println(\"Hallo, $(name)!\")\n    else\n        println(\"Hello, $(name)!\")\n    end\nend\n\ngreet(\"Denise\")\ngreet(\"Clara\")\ngreet(\"Marius\")\n\n\nHola, Denise!\nHallo, Clara!\nHello, Marius!\n\n\n\n\nExercise 3\nTask: Write a function which takes an array of numbers as input and returns their sum, without using the built-in function sum.\n\n\nSolution\nfunction mysum(arr)\n    res = zero(eltype(arr))\n    for x in arr\n        res += x\n    end\n    res\nend\n\n@show mysum([1,2,3,4,5]);\n\n\nmysum([1, 2, 3, 4, 5]) = 15\n\n\n\n\nExercise 4\nTask: Write a function which takes an array of numbers as input and returns their sum of squares.\n\n\nSolution\nsum_of_squares(arr) = sum(x -> x^2, arr) \n# or mapreduce(x -> x^2, +, arr)\n@show sum_of_squares([1,2,3]);\n\n\nsum_of_squares([1, 2, 3]) = 14\n\n\n\n\nExercise 5\nTask: Write a function which takes an array of numbers as input and returns the largest element.\n\n\nSolution\nlargest_element(arr) = findmax(arr)[1]\n@show largest_element([5,2,1,7]);\n\n\nlargest_element([5, 2, 1, 7]) = 7\n\n\n\n\nExercise 6\nTask: Write a function which takes an array of numbers as input and returns only those elements which are \\(>5\\). In a second step, write a more generic version which takes the limit as a second argument.\n\n\nSolution\ngreater_5(arr) = filter(>(5), arr)\ngreater_k(arr, k) = filter(>(k), arr)\n\n@show greater_5([1,2,3,4,5,6,7,8]);\n@show greater_k([1,2,3,4,5,6,7,8], 2);\n\n\ngreater_5([1, 2, 3, 4, 5, 6, 7, 8]) = [6, 7, 8]\ngreater_k([1, 2, 3, 4, 5, 6, 7, 8], 2) = [3, 4, 5, 6, 7, 8]\n\n\n\n\nExercise 7\nTask: Write a function which checks if an element is contained in an array.\n\n\nSolution\nx_in_arr(x, arr) = x in arr\n\n@show x_in_arr(\"Daniel\", [\"Denise\", \"Daniel\", \"Jakob\"]);\n\n\nx_in_arr(\"Daniel\", [\"Denise\", \"Daniel\", \"Jakob\"]) = true\n\n\n\n\nExercise 8\nWrite a function which takes a Matrix as input and returns the column-wise sums. In a second step, write a more generic version which takes an arbitrary reduction function (such as sum) as an additional argument and performs it column-wise.\n\n\nSolution\ncolsum(m) = sum(m; dims=1)\ncolop(op, m) = map(op, eachcol(m))\n\n@show colsum([1 2; 3 4]);\n@show colop(sum, [1 2; 3 4]);\n\n\ncolsum([1 2; 3 4]) = [4 6]\n\n\ncolop(sum, [1 2; 3 4]) = [4, 6]\n\n\n\n\nExercise 9\nWrite a function that concatenates two arrays. In a second step, write a function which concatenates two \\(n\\)-element arrays into a \\(n \\times 2\\) matrix.\n\n\nSolution\nconcatenate(a, b) = vcat(a, b)\nconcatenate_matrix(a, b) = hcat(a, b)\n\n@show concatenate([1,2], [3,4,5]);\n@show concatenate_matrix([1,2,3], [4,5,6]);\n\n\nconcatenate([1, 2], [3, 4, 5]) = [1, 2, 3, 4, 5]\n\n\nconcatenate_matrix([1, 2, 3], [4, 5, 6]) = [1 4; 2 5; 3 6]\n\n\n\n\nExercise 10\nWrite a function that takes a number and returns a function which multiplies its input by that number. Apply the generated function to each element of an array of 5 randomly generated numbers.\n\n\nSolution\ngenerate_mul_by_k(k) = x -> x * k\n\nmul_by_3 = generate_mul_by_k(3)\nmap(mul_by_3, rand(5))\n\n\n5-element Vector{Float64}:\n 0.4498511396899858\n 1.1177526184693598\n 1.4535104383430566\n 1.712135677023749\n 0.5874197081757649"
  }
]